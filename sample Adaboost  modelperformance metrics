from sklearn.ensemble import AdaBoostClassifier
import time

# Create an instance of the AdaBoostClassifier model
adaboost_model = AdaBoostClassifier(n_estimators=50, random_state=42)

# Start the timer to measure the training time
start = time.time()

# Fit the AdaBoost model to the training data
adaboost_model.fit(X_train_resampled, y_train_resampled)

# Stop the timer and calculate the training time
end = time.time()
print("Finished training within {:.2f} seconds".format(end - start))

# Predict the labels for the test set using the trained AdaBoost model
y_adaboost = adaboost_model.predict(X_test)

# Predict the class probabilities for the test set using the trained AdaBoost model
y_adaboost_prob = adaboost_model.predict_proba(X_test)

from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.calibration import CalibratedClassifierCV

# Create the AdaBoostClassifier model
adaboost_model = AdaBoostClassifier()

# Define the parameter grid for grid search
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 1.0],
    'algorithm': ['SAMME', 'SAMME.R']
}

# Create the GridSearchCV object with 5-fold cross-validation
grid_search = GridSearchCV(adaboost_model, param_grid, cv=10)

# Perform grid search to find the best hyperparameters
grid_search.fit(X_train_std, y_train)

# Get the best AdaBoostClassifier model with the optimal hyperparameters
best_adaboost_model = grid_search.best_estimator_

# Create the CalibratedClassifierCV object with 5-fold cross-validation
calibrated_model = CalibratedClassifierCV(best_adaboost_model, cv=10)

# Fit the calibrated model on the training data
calibrated_model.fit(X_train_resampled, y_train_resampled)

# Predict the test set results using the best calibrated model
y_adaboost = calibrated_model.predict(X_test)
y_adaboost_prob = calibrated_model.predict_proba(X_test)
accuracy_score_adaboost = accuracy_score(y_test, y_adaboost)
print("Accuracy score for AdaBoostClassifier: {:.2f}".format(accuracy_score_adaboost))

# Calculate precision, recall, and F1 scores
prec_adaboost = precision_score(y_test_, y_adaboost)
rec_adaboost = recall_score(y_test_, y_adaboost)
f1_adaboost = f1_score(y_test, y_adaboost)
print("Precision score for AdaBoostClassifier: {:.2f}".format(prec_adaboost))
print("Recall score for AdaBoostClassifier: {:.2f}".format(rec_adaboost))
print("F1 score for AdaBoostClassifier: {:.2f}".format(f1_adaboost))

# Calculate sensitivity, specificity, and AUC
tn, fp, fn, tp = confusion_matrix(y_test, y_adaboost).ravel()
sens_adaboost = tp / (tp + fn)
spec_adaboost = tn / (tn + fp)
fpr, tpr, _ = roc_curve(y_test, y_adaboost_prob[:, 1])
auc_adaboost = roc_auc_score(y_test, y_adaboost_prob[:, 1])

print("Sensitivity score for AdaBoostClassifier: {:.2f}".format(sens_adaboost))
print("Specificity score for AdaBoostClassifier: {:.2f}".format(spec_adaboost))
print("AUC score for AdaBoostClassifier: {:.3f}".format(auc_adaboost))
